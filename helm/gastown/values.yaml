# Gas Town Unified Helm Chart Configuration
# Components: Dolt SQL Server + BD Daemon + Redis (optional)
#
# DO NOT add environment-specific values files here (values/gastown-next.yaml, etc).
# This chart is published to OCI and env values bundled here will override the
# correct values in the fics-helm-chart deployment repo. All per-environment
# config belongs in fics-helm-chart/charts/gastown/values/.

nameOverride: ""
fullnameOverride: ""
imagePullSecrets: []

bd-daemon:
  imagePullSecrets: []

  # =============================================================================
  # Dolt SQL Server
  # =============================================================================
  dolt:
    statefulSet:
      enabled: true

    image:
      repository: dolthub/dolt-sql-server
      tag: "1.80.2"
      pullPolicy: IfNotPresent

    # Database name
    database: "dolt"

    # SQL server configuration
    config:
      host: "0.0.0.0"
      port: 3306
      max_connections: 100
      read_timeout_millis: 28800000
      write_timeout_millis: 28800000
      log_level: "info"

    # User configuration (root password via ExternalSecret)
    user:
      name: "root"

    # Init SQL to run on startup (optional)
    initSql: ""

    # S3 remote storage
    s3:
      enabled: false
      bucket: ""
      region: "us-east-1"
      dynamoTable: ""
      prefix: ""
      sync:
        pullOnStartup: true
        pushOnShutdown: true
        schedule:
          enabled: true
          intervalMinutes: 5
          gcEveryNCycles: 12
          squashEveryNCycles: 48
          squashThreshold: 100
      credentials:
        enabled: false
        secretName: "dolt-s3-credentials"

    # EKS Pod Identity for S3 access
    podIdentity:
      enabled: false
      clusterName: ""
      roleArn: ""

    # Persistence
    persistence:
      enabled: true
      storageClass: "gp3"
      accessMode: ReadWriteOnce
      size: 10Gi
      deleteClaim: false

    # Service
    service:
      type: ClusterIP
      port: 3306

    # Service Account
    serviceAccount:
      create: true
      name: ""
      annotations: {}

    # Resources
    resources:
      limits:
        cpu: 1000m
        memory: 2Gi
      requests:
        cpu: 250m
        memory: 512Mi

    # Probes
    livenessProbe:
      enabled: true
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 6

    readinessProbe:
      enabled: true
      initialDelaySeconds: 10
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 3

    # Pod scheduling
    nodeSelector: {}
    tolerations: []
    affinity: {}

    # Security contexts
    podSecurityContext:
      fsGroup: 1000

    securityContext:
      runAsUser: 1000
      runAsGroup: 1000
      runAsNonRoot: true

    # Termination grace period (allow time for S3 push)
    terminationGracePeriodSeconds: 60

  # =============================================================================
  # BD Daemon
  # =============================================================================
  image:
    repository: ghcr.io/groblegark/beads
    tag: "0.50.0-0ff2583c"
    pullPolicy: Always

  daemon:
    replicaCount: 1
    deploymentStrategy: Recreate
    priorityClassName: "production"

    # TCP server
    tcp:
      addr: ":9876"
      port: 9876

    # HTTP server (optional, enables public ingress)
    http:
      enabled: false
      addr: ":9080"
      port: 9080

    # TLS
    tls:
      enabled: false
      certManager:
        enabled: false
        issuerName: "letsencrypt-prod"
        issuerKind: "ClusterIssuer"
      existingSecret: ""

    # Logging
    logLevel: "info"
    logJSON: true

    # Service
    service:
      type: ClusterIP
      port: 9876
      httpPort: 9080

    # Service Account
    serviceAccount:
      create: true
      name: ""
      annotations: {}

    # Resources
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: 250m
        memory: 512Mi

    # Probes
    startupProbe:
      enabled: true
      initialDelaySeconds: 5
      periodSeconds: 5
      timeoutSeconds: 5
      failureThreshold: 30

    livenessProbe:
      enabled: true
      initialDelaySeconds: 5
      periodSeconds: 15
      timeoutSeconds: 10
      failureThreshold: 5

    readinessProbe:
      enabled: true
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 10
      failureThreshold: 6

    # Pod scheduling
    nodeSelector: {}
    tolerations: []
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
                - key: karpenter.sh/capacity-type
                  operator: In
                  values:
                    - on-demand
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: per-mr
                  operator: DoesNotExist

    # Security contexts
    podSecurityContext:
      fsGroup: 1000

    securityContext:
      runAsUser: 1000
      runAsGroup: 1000
      runAsNonRoot: true

  # =============================================================================
  # Redis (Bitnami subchart for ephemeral wisp storage)
  # =============================================================================
  redis:
    enabled: false
    external:
      url: ""
    namespace: ""
    wispTTL: ""
    architecture: standalone
    auth:
      enabled: false
    master:
      persistence:
        enabled: true
        size: 1Gi
    replica:
      replicaCount: 0

  # =============================================================================
  # NATS event bus (daemon, agents, slack-bot)
  # =============================================================================
  nats:
    enabled: true
    auth:
      enabled: false
    jetstream:
      maxMemory: 256M
    persistence:
      enabled: true
      storageClass: ""
      size: 2Gi
    image:
      registry: public.ecr.aws
      repository: docker/library/nats
      tag: "2.10-alpine"
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      limits:
        cpu: 500m
        memory: 512Mi

  # =============================================================================
  # External Secrets (merged for all components)
  # =============================================================================
  externalSecrets:
    enabled: true
    secretStoreKind: ClusterSecretStore
    secretStoreName: "aws-secretsmanager"
    refreshInterval: "15m"
    # Dolt root password
    doltRootPassword:
      remoteRef: ""
      property: "password"
    # S3 credentials for Dolt (legacy fallback, prefer Pod Identity)
    doltS3Credentials:
      enabled: false
      remoteRef: ""
      accessKeyIdProperty: "aws_access_key_id"
      secretAccessKeyProperty: "aws_secret_access_key"
    # BD daemon authentication token
    daemonToken:
      remoteRef: ""
      property: ""
    # Slack bot credentials (bot-token and app-token)
    slackBotCredentials:
      enabled: false
      remoteRef: ""
      botTokenProperty: "bot-token"
      appTokenProperty: "app-token"

  # =============================================================================
  # Slack Bot (sidecar in daemon pod)
  # =============================================================================
  slackBot:
    enabled: false
    image:
      repository: ghcr.io/groblegark/beads
      tag: ""  # defaults to daemon image tag if empty
      pullPolicy: Always
    secretName: "slack-bot-credentials"
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 100m
        memory: 128Mi

  # =============================================================================
  # Ingress (Traefik IngressRoute for daemon HTTP)
  # =============================================================================
  ingress:
    enabled: false
    host: ""
    ipWhitelist:
      enabled: false
      sourceRange: []
    rateLimit:
      enabled: true
      average: 100
      burst: 200

# =============================================================================
# Agent Controller (manages agent pods for beads automation)
# =============================================================================
agentController:
  enabled: false

  image:
    repository: ghcr.io/groblegark/agent-controller
    tag: "latest"
    pullPolicy: Always

  # Image used for agent pods spawned by the controller
  agentImage:
    repository: ghcr.io/groblegark/gastown-agent
    tag: "latest"

  replicaCount: 1

  # K8s secret name containing ANTHROPIC_API_KEY for agent pods
  apiKeySecret: ""

  # Coop sidecar image for agent pods (optional, enables PTY-based management)
  coopImage: ""

  # Use built-in coop binary instead of sidecar (requires coop compiled into agent image)
  coopBuiltin: false

  # K8s secret with Claude OAuth credentials for agent pods (Max/Corp accounts)
  # Mount as ~/.claude/.credentials.json. See scripts/sync-claude-credentials.sh
  credentialsSecret: ""

  # K8s secret with daemon auth token for agent pods (defaults to daemon token secret)
  daemonTokenSecret: ""

  # Gas Town deployment name (defaults to release name)
  townName: ""

  # NATS server URL for event bus integration (e.g., "nats://daemon-svc:4222")
  natsURL: ""

  # K8s secret with git credentials (username/token keys) for agent pods.
  # Created by gitCredentialsExternalSecret below, or manually.
  gitCredentialsSecret: ""

  # ExternalSecret config for git credentials (optional — creates the K8s Secret).
  # Set remoteRef + secretStoreName to enable.
  gitCredentialsExternalSecret: {}
  # gitCredentialsExternalSecret:
  #   secretStoreName: "aws-secretsmanager"
  #   secretStoreKind: ClusterSecretStore
  #   refreshInterval: "15m"
  #   remoteRef: "gastown/git-credentials"
  #   usernameProperty: "username"
  #   tokenProperty: "token"

  # K8s secret with NATS auth token for agent pods
  natsTokenSecret: ""

  serviceAccount:
    create: true
    name: ""
    annotations: {}

  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 256Mi

  # Broker coop URL (set when coopBroker is enabled in this chart)
  # Agent pods will receive COOP_BROKER_URL + COOP_BROKER_TOKEN env vars
  coopBrokerURL: ""
  coopBrokerTokenSecret: ""

  # Pod scheduling
  nodeSelector: {}
  tolerations: []
  affinity: {}

# =============================================================================
# Coop Broker — centralized OAuth credential broker + terminal multiplexer
# Runs coop in broker mode: manages credential refresh, distributes tokens,
# and multiplexes terminal views for all agent pods.
# =============================================================================
coopBroker:
  enabled: false

  image:
    repository: ghcr.io/groblegark/gastown/gastown-agent
    tag: "latest"
    pullPolicy: Always

  replicaCount: 1

  # Auth token for broker API (agent pods use this to register/authenticate)
  # If empty, uses the daemon token secret
  authTokenSecret: ""

  # K8s secret with Claude OAuth credentials (credentials.json key)
  # Used to seed the broker with initial refresh token on startup
  credentialsSecret: ""

  # NATS connection (auto-wired from bd-daemon NATS if empty)
  natsURL: ""

  # Persistence: write credentials to PVC so they survive restarts
  persistence:
    enabled: true
    size: 100Mi
    storageClass: ""
    path: "/var/lib/coop/credentials/credentials.json"

  # OAuth credential configuration
  credentials:
    accountName: "claude-max"
    provider: "claude"
    clientId: "9d1c"
    tokenUrl: "https://console.anthropic.com/v1/oauth/token"
    deviceAuthUrl: "https://console.anthropic.com/v1/oauth/device/code"
    refreshMarginSecs: 300
  # Additional accounts (list of {name, provider, clientId, tokenUrl, deviceAuthUrl, refreshMarginSecs})
  extraAccounts: []

  # ExternalSecret for OAuth refresh token
  externalSecret:
    enabled: false
    secretStoreName: "aws-secretsmanager"
    secretStoreKind: ClusterSecretStore
    refreshInterval: "15m"
    remoteRef: ""
    refreshTokenProperty: "refresh_token"

  # Ingress (Traefik IngressRoute)
  ingress:
    enabled: false
    host: ""
    ipWhitelist:
      enabled: false
      sourceRange: []

  # Service
  service:
    type: ClusterIP
    port: 8080
    healthPort: 9090

  # Resources (light — no PTY, no agent)
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 256Mi

  # Pod scheduling
  nodeSelector: {}
  tolerations: []
  affinity: {}

# =============================================================================
# Git Mirrors — in-cluster bare-repo mirrors for fast agent clones
# One Deployment + Service + PVC per rig. Agents clone from git://git-mirror-<name>:9418/
# =============================================================================
# gitMirrors:
#   beads:
#     enabled: true
#     url: "https://github.com/groblegark/beads.git"
#     storage: "2Gi"                    # PVC size for bare repo
#     storageClass: "gp2"               # Storage class
#     fetchIntervalSeconds: 300          # How often to fetch from upstream (default: 5m)
#     image: "alpine/git:latest"         # Git image (default: alpine/git:latest)
#     credentials:                       # Optional: for private repos
#       secretName: "git-creds-beads"    # K8s Secret name
#       type: "https"                    # "https" (git-credentials file) or "ssh" (ssh-privatekey)
#     resources:
#       requestsCPU: "50m"
#       requestsMemory: "64Mi"
#       limitsCPU: "200m"
#       limitsMemory: "256Mi"
gitMirrors: {}
